{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Response Modeling of Bank Marketing Campaign_\n",
    "\n",
    "\n",
    "### _Business Scenario_\n",
    "\n",
    "There has been a revenue decline for the Portuguese bank and they would like to know what actions to take. After investigation, we found out that the root cause is that their clients are not depositing as frequently as before. Knowing that term deposits allow banks to hold onto a deposit for a specific amount of time, so banks can invest in higher gain financial products to make a profit. In addition, banks also hold better chance to persuade term deposit clients into buying other products such as funds or insurance to further increase their revenues. As a result, the Portuguese bank would like to identify existing clients that have higher chance to subscribe for a term deposit and focus marketing effort on such clients.\n",
    "\n",
    "\n",
    "* The task is to build a POC for the problem\n",
    "\n",
    "* The data is related with direct marketing campaigns of a Portuguese banking institution. \n",
    "\n",
    "* The marketing campaigns were based on phone calls. \n",
    "\n",
    "* Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Attributes Information_\n",
    "\n",
    "\n",
    "### _Bank client data:_\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job \n",
    "(categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "\n",
    "3 - marital : marital status \n",
    "(categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "\n",
    "4 - education (categorical:'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "### _Data Related to the last contact of the current campaign:_\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone') \n",
    "\n",
    "9 - month: last contact month of year \n",
    "(categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "10 - day_of_week: last contact day of the week \n",
    "(categorical: 'mon','tue','wed','thu','fri')\n",
    "\n",
    "11 - duration: last contact duration, in seconds (numeric). \n",
    "Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "### _Other attributes:_\n",
    "\n",
    "12 - campaign: number of contacts performed during this campaign and for this client \n",
    "(numeric, includes last contact)\n",
    "\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign \n",
    "(numeric; 999 means client was not previously contacted)\n",
    "\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "### _Social and economic context attributes_\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric) \n",
    "\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n",
    "\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Exploratory Analysis_\n",
    "\n",
    "### _Import Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#!pip install imblearn\n",
    "#if the above command does not work to install imblearn package run the following command in your terminal\n",
    "# conda install -c glemaitre imbalanced-learn\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to print accuracy, precision and recall\n",
    "\n",
    "def convert_for_sklearn(label_list):\n",
    "    return [1 if i == 'yes' else 0 for i in label_list]\n",
    "\n",
    "\n",
    "def accuracy_precision_recall_metrics(y_true, y_pred):\n",
    "    \n",
    "    y_test_scoring = convert_for_sklearn(y_true)\n",
    "    test_pred_scoring = convert_for_sklearn(y_pred)\n",
    "\n",
    "    acc = accuracy_score(y_true= y_test_scoring, y_pred = test_pred_scoring)\n",
    "    prec = precision_score(y_true= y_test_scoring, y_pred = test_pred_scoring)\n",
    "    rec = recall_score(y_true= y_test_scoring, y_pred = test_pred_scoring)\n",
    "    \n",
    "    print(\"Test Precision: \",prec)\n",
    "    print(\"Test Recall: \",rec)\n",
    "    print(\"Test Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 22)\n",
      "(4119, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_no</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_no  age        job  marital    education credit_default housing  \\\n",
       "0            1   56  housemaid  married     basic.4y             no      no   \n",
       "1            2   57   services  married  high.school            NaN      no   \n",
       "2            3   37   services  married  high.school             no     yes   \n",
       "3            4   40     admin.  married     basic.6y             no      no   \n",
       "4            5   56   services  married  high.school             no      no   \n",
       "\n",
       "  loan    contact contacted_month ... campaign  pdays  previous     poutcome  \\\n",
       "0   no  telephone             may ...        1    999         0  nonexistent   \n",
       "1   no  telephone             may ...        1    999         0  nonexistent   \n",
       "2   no  telephone             may ...        1    999         0  nonexistent   \n",
       "3   no  telephone             may ...        1    999         0  nonexistent   \n",
       "4  yes  telephone             may ...        1    999         0  nonexistent   \n",
       "\n",
       "   emp_var_rate cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  \n",
       "0           1.1         93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1         93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1         93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1         93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1         93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading train and test data\n",
    "bank_data = pd.read_csv(\"bank-additional-full.csv\", sep=',', header=0, na_values='unknown')\n",
    "test_data =  pd.read_csv(\"test_cases.csv\", sep=',', header=0, na_values='unknown')\n",
    "\n",
    "print(bank_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_no          int64\n",
       "age                  int64\n",
       "job                 object\n",
       "marital             object\n",
       "education           object\n",
       "credit_default      object\n",
       "housing             object\n",
       "loan                object\n",
       "contact             object\n",
       "contacted_month     object\n",
       "day_of_week         object\n",
       "duration             int64\n",
       "campaign             int64\n",
       "pdays                int64\n",
       "previous             int64\n",
       "poutcome            object\n",
       "emp_var_rate       float64\n",
       "cons_price_idx     float64\n",
       "cons_conf_idx      float64\n",
       "euribor3m          float64\n",
       "nr_employed        float64\n",
       "y                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types of train data\n",
    "bank_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_no</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188.00000</td>\n",
       "      <td>40858</td>\n",
       "      <td>41108</td>\n",
       "      <td>39457</td>\n",
       "      <td>32591</td>\n",
       "      <td>40198</td>\n",
       "      <td>40198</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>...</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10422</td>\n",
       "      <td>24928</td>\n",
       "      <td>12168</td>\n",
       "      <td>32588</td>\n",
       "      <td>21576</td>\n",
       "      <td>33950</td>\n",
       "      <td>26144</td>\n",
       "      <td>13769</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>40.02406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081886</td>\n",
       "      <td>93.575664</td>\n",
       "      <td>-40.502600</td>\n",
       "      <td>3.621291</td>\n",
       "      <td>5167.035911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11890.09578</td>\n",
       "      <td>10.42125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.570960</td>\n",
       "      <td>0.578840</td>\n",
       "      <td>4.628198</td>\n",
       "      <td>1.734447</td>\n",
       "      <td>72.251528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10297.75000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30891.25000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_no          age     job  marital          education  \\\n",
       "count   41188.00000  41188.00000   40858    41108              39457   \n",
       "unique          NaN          NaN      11        3                  7   \n",
       "top             NaN          NaN  admin.  married  university.degree   \n",
       "freq            NaN          NaN   10422    24928              12168   \n",
       "mean    20594.50000     40.02406     NaN      NaN                NaN   \n",
       "std     11890.09578     10.42125     NaN      NaN                NaN   \n",
       "min         1.00000     17.00000     NaN      NaN                NaN   \n",
       "25%     10297.75000     32.00000     NaN      NaN                NaN   \n",
       "50%     20594.50000     38.00000     NaN      NaN                NaN   \n",
       "75%     30891.25000     47.00000     NaN      NaN                NaN   \n",
       "max     41188.00000     98.00000     NaN      NaN                NaN   \n",
       "\n",
       "       credit_default housing   loan   contact contacted_month  ...    \\\n",
       "count           32591   40198  40198     41188           41188  ...     \n",
       "unique              2       2      2         2              10  ...     \n",
       "top                no     yes     no  cellular             may  ...     \n",
       "freq            32588   21576  33950     26144           13769  ...     \n",
       "mean              NaN     NaN    NaN       NaN             NaN  ...     \n",
       "std               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "min               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "25%               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "50%               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "75%               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "max               NaN     NaN    NaN       NaN             NaN  ...     \n",
       "\n",
       "            campaign         pdays      previous     poutcome  emp_var_rate  \\\n",
       "count   41188.000000  41188.000000  41188.000000        41188  41188.000000   \n",
       "unique           NaN           NaN           NaN            3           NaN   \n",
       "top              NaN           NaN           NaN  nonexistent           NaN   \n",
       "freq             NaN           NaN           NaN        35563           NaN   \n",
       "mean        2.567593    962.475454      0.172963          NaN      0.081886   \n",
       "std         2.770014    186.910907      0.494901          NaN      1.570960   \n",
       "min         1.000000      0.000000      0.000000          NaN     -3.400000   \n",
       "25%         1.000000    999.000000      0.000000          NaN     -1.800000   \n",
       "50%         2.000000    999.000000      0.000000          NaN      1.100000   \n",
       "75%         3.000000    999.000000      0.000000          NaN      1.400000   \n",
       "max        56.000000    999.000000      7.000000          NaN      1.400000   \n",
       "\n",
       "       cons_price_idx  cons_conf_idx     euribor3m   nr_employed      y  \n",
       "count    41188.000000   41188.000000  41188.000000  41188.000000  41188  \n",
       "unique            NaN            NaN           NaN           NaN      2  \n",
       "top               NaN            NaN           NaN           NaN     no  \n",
       "freq              NaN            NaN           NaN           NaN  36548  \n",
       "mean        93.575664     -40.502600      3.621291   5167.035911    NaN  \n",
       "std          0.578840       4.628198      1.734447     72.251528    NaN  \n",
       "min         92.201000     -50.800000      0.634000   4963.600000    NaN  \n",
       "25%         93.075000     -42.700000      1.344000   5099.100000    NaN  \n",
       "50%         93.749000     -41.800000      4.857000   5191.000000    NaN  \n",
       "75%         93.994000     -36.400000      4.961000   5228.100000    NaN  \n",
       "max         94.767000     -26.900000      5.045000   5228.100000    NaN  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of the data\n",
    "bank_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university.degree      12168\n",
      "high.school             9515\n",
      "basic.9y                6045\n",
      "professional.course     5243\n",
      "basic.4y                4176\n",
      "basic.6y                2292\n",
      "illiterate                18\n",
      "Name: education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replacing various category to one single category as basic\n",
    "print(bank_data.education.value_counts())\n",
    "bank_data.replace(['basic.6y','basic.4y', 'basic.9y'], 'basic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basic                  12513\n",
       "university.degree      12168\n",
       "high.school             9515\n",
       "professional.course     5243\n",
       "illiterate                18\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts of each level in education\n",
    "bank_data.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank_data.drop(\"customer_no\", axis = 1, inplace= True)\n",
    "# test_data.drop(\"customer_no\", axis = 1, inplace= True)\n",
    "# bank_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type casting columns to required data type\n",
    "for col in ['job', 'marital', 'education', 'credit_default', 'housing', 'loan', 'contact', 'contacted_month', 'day_of_week', 'poutcome', 'y']:\n",
    "    bank_data[col] = bank_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting columns to numeric and categorical types\n",
    "cat_attr = list(bank_data.select_dtypes(\"category\").columns)\n",
    "num_attr = list(bank_data.columns.difference(cat_attr))\n",
    "\n",
    "# Removing target variable\n",
    "cat_attr.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'credit_default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'contacted_month',\n",
       " 'day_of_week',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing categorical column names\n",
    "cat_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'campaign',\n",
       " 'cons_conf_idx',\n",
       " 'cons_price_idx',\n",
       " 'customer_no',\n",
       " 'duration',\n",
       " 'emp_var_rate',\n",
       " 'euribor3m',\n",
       " 'nr_employed',\n",
       " 'pdays',\n",
       " 'previous']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing numeric column names\n",
    "num_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_no           0\n",
       "age                   0\n",
       "job                 330\n",
       "marital              80\n",
       "education          1731\n",
       "credit_default     8597\n",
       "housing             990\n",
       "loan                990\n",
       "contact               0\n",
       "contacted_month       0\n",
       "day_of_week           0\n",
       "duration              0\n",
       "campaign              0\n",
       "pdays                 0\n",
       "previous              0\n",
       "poutcome              0\n",
       "emp_var_rate          0\n",
       "cons_price_idx        0\n",
       "cons_conf_idx         0\n",
       "euribor3m             0\n",
       "nr_employed           0\n",
       "y                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "bank_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping target variable before train-test split\n",
    "X = bank_data.drop([\"y\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving target variable for train-test split\n",
    "y = bank_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_no', 'age', 'job', 'marital', 'education', 'credit_default',\n",
       "       'housing', 'loan', 'contact', 'contacted_month', 'day_of_week',\n",
       "       'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate',\n",
       "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying columns\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21) (41188,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of data\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32950, 21)\n",
      "(8238, 21)\n",
      "(32950,)\n",
      "(8238,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying train and test data\n",
    "import copy\n",
    "X_train_bu = copy.deepcopy(X_train)\n",
    "X_test_bu = copy.deepcopy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>35</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40128</th>\n",
       "      <td>22</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.215</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0.835</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11388</th>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>25</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>442</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>37</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job  marital            education credit_default housing  \\\n",
       "5402    35  entrepreneur  married          high.school             no      no   \n",
       "40128   22      services   single  professional.course             no      no   \n",
       "11388   38   blue-collar  married                  NaN             no     yes   \n",
       "16361   25   blue-collar   single                basic            NaN     yes   \n",
       "23389   37    technician  married    university.degree             no      no   \n",
       "\n",
       "      loan    contact contacted_month day_of_week  duration  campaign  pdays  \\\n",
       "5402    no  telephone             may         fri       178         2    999   \n",
       "40128   no   cellular             jul         tue       256         3    999   \n",
       "11388   no  telephone             jun         fri        42         5    999   \n",
       "16361   no   cellular             jul         wed       442         2    999   \n",
       "23389   no   cellular             aug         wed       107         4    999   \n",
       "\n",
       "       previous     poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "5402          0  nonexistent           1.1          93.994          -36.4   \n",
       "40128         1      failure          -1.7          94.215          -40.3   \n",
       "11388         0  nonexistent           1.4          94.465          -41.8   \n",
       "16361         0  nonexistent           1.4          93.918          -42.7   \n",
       "23389         0  nonexistent           1.4          93.444          -36.1   \n",
       "\n",
       "       euribor3m  nr_employed  \n",
       "5402       4.857       5191.0  \n",
       "40128      0.835       4991.6  \n",
       "11388      4.959       5228.1  \n",
       "16361      4.963       5228.1  \n",
       "23389      4.964       5228.1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping customer_no columns from both train and test data\n",
    "X_train.drop(\"customer_no\", axis = 1, inplace= True)\n",
    "X_test.drop(\"customer_no\", axis = 1, inplace= True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'credit_default', 'housing',\n",
       "       'loan', 'contact', 'contacted_month', 'day_of_week', 'duration',\n",
       "       'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate',\n",
       "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>42</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.865</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38463</th>\n",
       "      <td>37</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cellular</td>\n",
       "      <td>oct</td>\n",
       "      <td>fri</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>92.431</td>\n",
       "      <td>-26.9</td>\n",
       "      <td>0.730</td>\n",
       "      <td>5017.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>407</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>42</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37164</th>\n",
       "      <td>56</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.884</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job  marital          education credit_default housing  \\\n",
       "8107    42      services  married        high.school             no      no   \n",
       "38463   37   blue-collar  married              basic             no     NaN   \n",
       "1933    41   blue-collar  married              basic            NaN      no   \n",
       "8352    42        admin.  married  university.degree            NaN     yes   \n",
       "37164   56  entrepreneur  married        high.school             no     yes   \n",
       "\n",
       "      loan    contact contacted_month day_of_week  duration  campaign  pdays  \\\n",
       "8107    no  telephone             jun         mon       217         4    999   \n",
       "38463  NaN   cellular             oct         fri        93         1    999   \n",
       "1933    no  telephone             may         fri       407         4    999   \n",
       "8352    no  telephone             jun         tue       215         3    999   \n",
       "37164   no   cellular             aug         wed       131         5    999   \n",
       "\n",
       "       previous     poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "8107          0  nonexistent           1.4          94.465          -41.8   \n",
       "38463         0  nonexistent          -3.4          92.431          -26.9   \n",
       "1933          0  nonexistent           1.1          93.994          -36.4   \n",
       "8352          0  nonexistent           1.4          94.465          -41.8   \n",
       "37164         1      failure          -2.9          92.201          -31.4   \n",
       "\n",
       "       euribor3m  nr_employed  \n",
       "8107       4.865       5228.1  \n",
       "38463      0.730       5017.5  \n",
       "1933       4.855       5191.0  \n",
       "8352       4.864       5228.1  \n",
       "37164      0.884       5076.2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     29250\n",
      "yes     3700\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of levels in target variable in train data\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     7298\n",
      "yes     940\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of levels in target variable in test data\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "job                 261\n",
       "marital              66\n",
       "education          1372\n",
       "credit_default     6926\n",
       "housing             790\n",
       "loan                790\n",
       "contact               0\n",
       "contacted_month       0\n",
       "day_of_week           0\n",
       "duration              0\n",
       "campaign              0\n",
       "pdays                 0\n",
       "previous              0\n",
       "poutcome              0\n",
       "emp_var_rate          0\n",
       "cons_price_idx        0\n",
       "cons_conf_idx         0\n",
       "euribor3m             0\n",
       "nr_employed           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values in train data\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "job                  69\n",
       "marital              14\n",
       "education           359\n",
       "credit_default     1671\n",
       "housing             200\n",
       "loan                200\n",
       "contact               0\n",
       "contacted_month       0\n",
       "day_of_week           0\n",
       "duration              0\n",
       "campaign              0\n",
       "pdays                 0\n",
       "previous              0\n",
       "poutcome              0\n",
       "emp_var_rate          0\n",
       "cons_price_idx        0\n",
       "cons_conf_idx         0\n",
       "euribor3m             0\n",
       "nr_employed           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values in test data\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing categorical data with mode\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on train data\n",
    "X_train[cat_attr] = cat_imputer.fit_transform(X_train[cat_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on test data\n",
    "X_test[cat_attr] = cat_imputer.fit_transform(X_test[cat_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'campaign',\n",
       " 'cons_conf_idx',\n",
       " 'cons_price_idx',\n",
       " 'duration',\n",
       " 'emp_var_rate',\n",
       " 'euribor3m',\n",
       " 'nr_employed',\n",
       " 'pdays',\n",
       " 'previous']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing customer_no from numerical attribute\n",
    "num_attr.remove('customer_no')\n",
    "num_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation on numeric attribute using median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X_train[num_attr] = num_imputer.fit_transform(X_train[num_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[num_attr] = num_imputer.fit_transform(X_test[num_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "job                0\n",
       "marital            0\n",
       "education          0\n",
       "credit_default     0\n",
       "housing            0\n",
       "loan               0\n",
       "contact            0\n",
       "contacted_month    0\n",
       "day_of_week        0\n",
       "duration           0\n",
       "campaign           0\n",
       "pdays              0\n",
       "previous           0\n",
       "poutcome           0\n",
       "emp_var_rate       0\n",
       "cons_price_idx     0\n",
       "cons_conf_idx      0\n",
       "euribor3m          0\n",
       "nr_employed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if imputed correctly\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "job                0\n",
       "marital            0\n",
       "education          0\n",
       "credit_default     0\n",
       "housing            0\n",
       "loan               0\n",
       "contact            0\n",
       "contacted_month    0\n",
       "day_of_week        0\n",
       "duration           0\n",
       "campaign           0\n",
       "pdays              0\n",
       "previous           0\n",
       "poutcome           0\n",
       "emp_var_rate       0\n",
       "cons_price_idx     0\n",
       "cons_conf_idx      0\n",
       "euribor3m          0\n",
       "nr_employed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if imputed correctly\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train= pd.get_dummies(X_train, drop_first=True)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding categorical data\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['job'] = label_encoder.fit_transform(X_train['job'])\n",
    "X_train['marital'] = label_encoder.fit_transform(X_train['marital'])\n",
    "X_train['education'] = label_encoder.fit_transform(X_train['education'])\n",
    "X_train['credit_default'] = label_encoder.fit_transform(X_train['credit_default'])\n",
    "X_train['housing'] = label_encoder.fit_transform(X_train['housing'])\n",
    "X_train['loan'] = label_encoder.fit_transform(X_train['loan'])\n",
    "X_train['contact'] = label_encoder.fit_transform(X_train['contact'])\n",
    "X_train['contacted_month'] = label_encoder.fit_transform(X_train['contacted_month'])\n",
    "X_train['day_of_week'] = label_encoder.fit_transform(X_train['day_of_week'])\n",
    "X_train['poutcome'] = label_encoder.fit_transform(X_train['poutcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['job'] = label_encoder.fit_transform(X_test['job'])\n",
    "X_test['marital'] = label_encoder.fit_transform(X_test['marital'])\n",
    "X_test['education'] = label_encoder.fit_transform(X_test['education'])\n",
    "X_test['credit_default'] = label_encoder.fit_transform(X_test['credit_default'])\n",
    "X_test['housing'] = label_encoder.fit_transform(X_test['housing'])\n",
    "X_test['loan'] = label_encoder.fit_transform(X_test['loan'])\n",
    "X_test['contact'] = label_encoder.fit_transform(X_test['contact'])\n",
    "X_test['contacted_month'] = label_encoder.fit_transform(X_test['contacted_month'])\n",
    "X_test['day_of_week'] = label_encoder.fit_transform(X_test['day_of_week'])\n",
    "X_test['poutcome'] = label_encoder.fit_transform(X_test['poutcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40128</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.215</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0.835</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11388</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>442.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>37.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  job  marital  education  credit_default  housing  loan  contact  \\\n",
       "5402   35.0    2        1          1               0        0     0        1   \n",
       "40128  22.0    7        2          3               0        0     0        0   \n",
       "11388  38.0    1        1          0               0        1     0        1   \n",
       "16361  25.0    1        2          0               0        1     0        0   \n",
       "23389  37.0    9        1          4               0        0     0        0   \n",
       "\n",
       "       contacted_month  day_of_week  duration  campaign  pdays  previous  \\\n",
       "5402                 6            0     178.0       2.0  999.0       0.0   \n",
       "40128                3            3     256.0       3.0  999.0       1.0   \n",
       "11388                4            0      42.0       5.0  999.0       0.0   \n",
       "16361                3            4     442.0       2.0  999.0       0.0   \n",
       "23389                1            4     107.0       4.0  999.0       0.0   \n",
       "\n",
       "       poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
       "5402          1           1.1          93.994          -36.4      4.857   \n",
       "40128         0          -1.7          94.215          -40.3      0.835   \n",
       "11388         1           1.4          94.465          -41.8      4.959   \n",
       "16361         1           1.4          93.918          -42.7      4.963   \n",
       "23389         1           1.4          93.444          -36.1      4.964   \n",
       "\n",
       "       nr_employed  \n",
       "5402        5191.0  \n",
       "40128       4991.6  \n",
       "11388       5228.1  \n",
       "16361       5228.1  \n",
       "23389       5228.1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                float64\n",
       "job                  int32\n",
       "marital              int32\n",
       "education            int32\n",
       "credit_default       int32\n",
       "housing              int32\n",
       "loan                 int32\n",
       "contact              int32\n",
       "contacted_month      int32\n",
       "day_of_week          int32\n",
       "duration           float64\n",
       "campaign           float64\n",
       "pdays              float64\n",
       "previous           float64\n",
       "poutcome             int32\n",
       "emp_var_rate       float64\n",
       "cons_price_idx     float64\n",
       "cons_conf_idx      float64\n",
       "euribor3m          float64\n",
       "nr_employed        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data types\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising numerical data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_attr])\n",
    "\n",
    "X_train[num_attr]=scaler.transform(X_train[num_attr])\n",
    "X_test[num_attr]=scaler.transform(X_test[num_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>contacted_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>-0.481846</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.310570</td>\n",
       "      <td>-0.204850</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>-0.349924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643045</td>\n",
       "      <td>0.720048</td>\n",
       "      <td>0.883266</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.326210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40128</th>\n",
       "      <td>-1.730916</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.009892</td>\n",
       "      <td>0.162686</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.674657</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.140950</td>\n",
       "      <td>1.101751</td>\n",
       "      <td>0.039589</td>\n",
       "      <td>-1.616536</td>\n",
       "      <td>-2.444456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11388</th>\n",
       "      <td>-0.193599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.834829</td>\n",
       "      <td>0.897757</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>-0.349924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834187</td>\n",
       "      <td>1.533541</td>\n",
       "      <td>-0.284902</td>\n",
       "      <td>0.766454</td>\n",
       "      <td>0.841715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>-1.442669</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.707109</td>\n",
       "      <td>-0.204850</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>-0.349924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834187</td>\n",
       "      <td>0.588783</td>\n",
       "      <td>-0.479597</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>0.841715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>-0.289682</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.584264</td>\n",
       "      <td>0.530222</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>-0.349924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834187</td>\n",
       "      <td>-0.229892</td>\n",
       "      <td>0.948164</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.841715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  job  marital  education  credit_default  housing  loan  \\\n",
       "5402  -0.481846    2        1          1               0        0     0   \n",
       "40128 -1.730916    7        2          3               0        0     0   \n",
       "11388 -0.193599    1        1          0               0        1     0   \n",
       "16361 -1.442669    1        2          0               0        1     0   \n",
       "23389 -0.289682    9        1          4               0        0     0   \n",
       "\n",
       "       contact  contacted_month  day_of_week  duration  campaign     pdays  \\\n",
       "5402         1                6            0 -0.310570 -0.204850  0.195582   \n",
       "40128        0                3            3 -0.009892  0.162686  0.195582   \n",
       "11388        1                4            0 -0.834829  0.897757  0.195582   \n",
       "16361        0                3            4  0.707109 -0.204850  0.195582   \n",
       "23389        0                1            4 -0.584264  0.530222  0.195582   \n",
       "\n",
       "       previous  poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "5402  -0.349924         1      0.643045        0.720048       0.883266   \n",
       "40128  1.674657         0     -1.140950        1.101751       0.039589   \n",
       "11388 -0.349924         1      0.834187        1.533541      -0.284902   \n",
       "16361 -0.349924         1      0.834187        0.588783      -0.479597   \n",
       "23389 -0.349924         1      0.834187       -0.229892       0.948164   \n",
       "\n",
       "       euribor3m  nr_employed  \n",
       "5402    0.707515     0.326210  \n",
       "40128  -1.616536    -2.444456  \n",
       "11388   0.766454     0.841715  \n",
       "16361   0.768765     0.841715  \n",
       "23389   0.769343     0.841715  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying top data after label encoding and standardising\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predictions on train data\n",
    "y_pred1=logreg.predict(X_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred2=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy Score on Train set ->  90.99241274658574\n",
      "Logistic Accuracy Score on Validation set ->  91.1143481427531\n"
     ]
    }
   ],
   "source": [
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Logistic Accuracy Score on Train set -> \", accuracy_score(y_train, y_pred1)*100)\n",
    "print(\"Logistic Accuracy Score on Validation set -> \", accuracy_score(y_test, y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252518177573211"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train,y_pred1,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302656345499543"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'logreg_model.sav'\n",
    "# pickle.dump(logreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# filename = 'logreg_model.sav'\n",
    "# loaded_model1 = pickle.load(open(filename, 'rb'))\n",
    "# result1 = loaded_model1.score(X_test, y_test)\n",
    "# print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'no', 'no', ..., 'no', 'no', 'no'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred1 = best_model.predict(X_train)\n",
    "ypred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'no', 'no', ..., 'no', 'no', 'no'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred2 = best_model.predict(X_test)\n",
    "ypred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy Score on Train set ->  90.99241274658574\n",
      "Logistic Accuracy Score on Validation set ->  91.10220927409566\n",
      "0.7252518177573211\n",
      "0.7300600425961659\n"
     ]
    }
   ],
   "source": [
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Logistic Accuracy Score on Train set -> \", accuracy_score(y_train, ypred1)*100)\n",
    "print(\"Logistic Accuracy Score on Validation set -> \", accuracy_score(y_test, ypred2)*100)\n",
    "\n",
    "print(f1_score(y_train,ypred1,average='macro'))\n",
    "\n",
    "print(f1_score(y_test,ypred2,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'logreg_model1.sav'\n",
    "# pickle.dump(clf1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model2 = pickle.load(open(filename, 'rb'))\n",
    "# result2 = loaded_model2.score(X_test, y_test)\n",
    "# print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score on Train set ->  71.95447647951441\n",
      "Naive Bayes Accuracy Score on Validation set ->  71.29157562515174\n",
      "0.6068894149600741\n",
      "0.6058875130361114\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.GaussianNB()\n",
    "Naive.fit(X_train,y_train)\n",
    "\n",
    "# predict the labels on train dataset\n",
    "y_pred3 = Naive.predict(X_train)\n",
    "# predict the labels on validation dataset\n",
    "y_pred4 = Naive.predict(X_test)\n",
    "\n",
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score on Train set -> \", accuracy_score(y_train, y_pred3)*100)\n",
    "print(\"Naive Bayes Accuracy Score on Validation set -> \", accuracy_score(y_test, y_pred4)*100)\n",
    "\n",
    "print(f1_score(y_train,y_pred3,average='macro'))\n",
    "print(f1_score(y_test,y_pred4,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'naivebayes_model.sav'\n",
    "# pickle.dump(Naive, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model3 = pickle.load(open(filename, 'rb'))\n",
    "# result3 = loaded_model3.score(X_test, y_test)\n",
    "# print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of parameters to test\n",
    "param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"min_samples_split\": [10, 20],\n",
    "              \"max_depth\": [None, 5, 10],\n",
    "              \"min_samples_leaf\": [5, 10],\n",
    "              \"max_leaf_nodes\": [10, 20],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 5, 10], 'max_leaf_nodes': [10, 20],\n",
       "                         'min_samples_leaf': [5, 10],\n",
       "                         'min_samples_split': [10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dt, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=20,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = clf.predict(X_train)\n",
    "y_pred6 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9597606837606838\n",
      "Train TPR:  0.5908108108108108\n",
      "Train Accuracy:  0.9183308042488619\n",
      "Test TNR:  0.9564264181967662\n",
      "Test TPR:  0.5914893617021276\n",
      "Test Accuracy:  0.9147851420247632\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(y_train, y_pred5)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred6)\n",
    "\n",
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)\n",
    "\n",
    "Accuracy_Test=(confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test= confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test= confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866319492066105"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train,y_pred5,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825655261363857"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred6, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'dt_model.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model4 = pickle.load(open(filename, 'rb'))\n",
    "# result4 = loaded_model4.score(X_test, y_test)\n",
    "# print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = SVC(kernel='linear', C=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm.fit(X=X_train, y= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = linear_svm.predict(X_train)\n",
    "y_pred8 = linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Conf Matrix : \n",
      " [[28654   596]\n",
      " [ 2664  1036]]\n",
      "\n",
      "TRAIN DATA ACCURACY 0.9010622154779969\n"
     ]
    }
   ],
   "source": [
    "### Train data accuracy\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "print(\"TRAIN Conf Matrix : \\n\", confusion_matrix(y_train, y_pred7))\n",
    "print(\"\\nTRAIN DATA ACCURACY\",accuracy_score(y_train,y_pred7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.38859714928732186\n",
      "\n",
      "Train data f1-score for class 'no' 0.9461761986527539\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred7,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred7,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall_average = recall_score(y_train, y_pred7, average=\"binary\", pos_label=\"yes\")\n",
    "# print(recall_average)\n",
    "\n",
    "# recall_average1 = recall_score(y_test, y_pred8, average=\"binary\", pos_label=\"yes\")\n",
    "# print(recall_average1)\n",
    "\n",
    "# import sklearn.metrics as metrics\n",
    "# from sklearn.metrics import precision_score\n",
    "# print(\"Precision:\",metrics.precision_score(y_test, y_pred8, pos_label='yes'))\n",
    "#print(\"Precision:\",metrics.precision_score(y_test, y_pred8, pos_label='yes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Conf Matrix : \n",
      " [[7172  126]\n",
      " [ 669  271]]\n",
      "\n",
      "TEST DATA ACCURACY 0.903495994173343\n"
     ]
    }
   ],
   "source": [
    "### Test data accuracy\n",
    "print(\"TEST Conf Matrix : \\n\", confusion_matrix(y_test, y_pred8))\n",
    "print(\"\\nTEST DATA ACCURACY\",accuracy_score(y_test,y_pred8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data f1-score for class 'yes' 0.4053851907255049\n",
      "\n",
      "Test data f1-score for class 'no' 0.9474866239513838\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred8,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred8,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'svclinear_model.sav'\n",
    "# pickle.dump(linear_svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model5 = pickle.load(open(filename, 'rb'))\n",
    "# result5 = loaded_model5.score(X_test, y_test)\n",
    "# print(result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an SVC object and print it to see the arguments\n",
    "svc = SVC(kernel='rbf', random_state=0, gamma=0.01, C=1)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "svc.fit(X=X_train, y= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred9 = svc.predict(X_train)\n",
    "y_pred10 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Conf Matrix : \n",
      " [[28764   486]\n",
      " [ 2570  1130]]\n",
      "\n",
      "TRAIN DATA ACCURACY 0.9072534142640364\n",
      "\n",
      "Train data f1-score for class 'yes' 0.4251316779533484\n",
      "\n",
      "Train data f1-score for class 'no' 0.949557638980589\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST Conf Matrix : \n",
      " [[7187  111]\n",
      " [ 632  308]]\n",
      "\n",
      "TEST DATA ACCURACY 0.9098082058752124\n",
      "\n",
      "Test data f1-score for class 'yes' 0.4532744665194996\n",
      "\n",
      "Test data f1-score for class 'no' 0.9508500363828803\n"
     ]
    }
   ],
   "source": [
    "### Train data accuracy\n",
    "\n",
    "print(\"TRAIN Conf Matrix : \\n\", confusion_matrix(y_train, y_pred9))\n",
    "print(\"\\nTRAIN DATA ACCURACY\",accuracy_score(y_train,y_pred9))\n",
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred9,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred9,pos_label=\"no\"))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "\n",
    "print(\"TEST Conf Matrix : \\n\", confusion_matrix(y_test, y_pred10))\n",
    "print(\"\\nTEST DATA ACCURACY\",accuracy_score(y_test,y_pred10))\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred10,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred10,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'svcrbf_model.sav'\n",
    "# pickle.dump(svc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model6 = pickle.load(open(filename, 'rb'))\n",
    "# result6 = loaded_model6.score(X_test, y_test)\n",
    "# print(result6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_grid = SVC() \n",
    "# param_grid = { \n",
    "#                 'C': [0.1, 1],\n",
    "#                 'gamma': [0.1, 1], \n",
    "#                 'kernel':['linear', 'rbf', 'poly' ]\n",
    "#              }\n",
    "\n",
    "# svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "#svc_cv_grid.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "#svc_cv_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc_best = svc_cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict\n",
    "# train_predictions = svc_best.predict(X_train)\n",
    "# test_predictions = svc_best.predict(X_test)\n",
    "# y_pred11 = svc_best.predict(X_train)\n",
    "# y_pred12 = svc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,y_pred11))\n",
    "# print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred11,pos_label=\"yes\"))\n",
    "# print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred11,pos_label=\"no\"))\n",
    "\n",
    "# ### Test data accuracy\n",
    "# print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "# print(\"TEST DATA ACCURACY\",accuracy_score(y_test,y_pred12))\n",
    "# print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred12,pos_label=\"yes\"))\n",
    "# print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred12,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'svcgridsearch_model.sav'\n",
    "# pickle.dump(svc_cv_grid, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model7 = pickle.load(open(filename, 'rb'))\n",
    "# result7 = loaded_model7.score(X_test, y_test)\n",
    "# print(result7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=10,max_depth=8)\n",
    "clf2.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred13 = clf2.predict(X_train)\n",
    "y_pred14 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9222154779969651\n",
      "\n",
      "Train data f1-score for class 'yes' 0.5440313111545988\n",
      "\n",
      "Train data f1-score for class 'no' 0.9574810464672607\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.9107793153678078\n",
      "\n",
      "Test data f1-score for class 'yes' 0.49760765550239233\n",
      "\n",
      "Test data f1-score for class 'no' 0.9510424298940918\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,y_pred13))\n",
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred13,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred13,pos_label=\"no\"))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,y_pred14))\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred14,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred14,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'rf_model.sav'\n",
    "# pickle.dump(clf2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model8 = pickle.load(open(filename, 'rb'))\n",
    "# result8 = loaded_model8.score(X_test, y_test)\n",
    "# print(result8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, max_features='sqrt') \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\"n_estimators\" : [9, 18],\n",
    "              \"max_depth\" : [2,3],\n",
    "              \"min_samples_leaf\" : [2, 4]\n",
    "             }\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "\n",
      "Best parameters set found on training set:\n",
      "\n",
      "\n",
      "{'max_depth': 2, 'min_samples_leaf': 4, 'n_estimators': 18}\n",
      "\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "\n",
      "0.838 for {'max_depth': 2, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "0.840 for {'max_depth': 2, 'min_samples_leaf': 2, 'n_estimators': 18}\n",
      "0.819 for {'max_depth': 2, 'min_samples_leaf': 4, 'n_estimators': 9}\n",
      "0.854 for {'max_depth': 2, 'min_samples_leaf': 4, 'n_estimators': 18}\n",
      "0.824 for {'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "0.844 for {'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 18}\n",
      "0.821 for {'max_depth': 3, 'min_samples_leaf': 4, 'n_estimators': 9}\n",
      "0.835 for {'max_depth': 3, 'min_samples_leaf': 4, 'n_estimators': 18}\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "\n",
      "Best parameters set found on training set:\n",
      "\n",
      "\n",
      "{'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "\n",
      "0.573 for {'max_depth': 2, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "0.574 for {'max_depth': 2, 'min_samples_leaf': 2, 'n_estimators': 18}\n",
      "0.552 for {'max_depth': 2, 'min_samples_leaf': 4, 'n_estimators': 9}\n",
      "0.555 for {'max_depth': 2, 'min_samples_leaf': 4, 'n_estimators': 18}\n",
      "0.585 for {'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "0.583 for {'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 18}\n",
      "0.581 for {'max_depth': 3, 'min_samples_leaf': 4, 'n_estimators': 9}\n",
      "0.584 for {'max_depth': 3, 'min_samples_leaf': 4, 'n_estimators': 18}\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    clf3 = GridSearchCV(estimator=rfc, param_grid=param_grid,cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf3.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print(\"\\n\")\n",
    "    print(clf3.best_params_)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Grid scores on training set:\")\n",
    "    print(\"\\n\")\n",
    "    means = clf3.cv_results_['mean_test_score']\n",
    "    for mean, params in zip(means, clf3.cv_results_['params']):\n",
    "        print(\"%0.3f for %r\" % (mean, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred15=clf3.predict(X_train)\n",
    "ypred16=clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29082   168]\n",
      " [ 3138   562]]\n",
      "[[7262   36]\n",
      " [ 782  158]]\n",
      "0.8996661608497724\n",
      "0.9007040543821316\n",
      "\n",
      "Train data f1-score for class 'yes' 0.25372460496613997\n",
      "\n",
      "Train data f1-score for class 'no' 0.9462176671547096\n",
      "\n",
      "Test data f1-score for class 'yes' 0.27865961199294537\n",
      "\n",
      "Test data f1-score for class 'no' 0.9466823099986964\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, ypred15))\n",
    "\n",
    "print(confusion_matrix(y_test, ypred16))\n",
    "\n",
    "print(accuracy_score(y_train,ypred15))\n",
    "\n",
    "print(accuracy_score(y_test,ypred16))\n",
    "\n",
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,ypred15,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,ypred15,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,ypred16,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,ypred16,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'rf_gridsearch_model.sav'\n",
    "# pickle.dump(clf3, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model9 = pickle.load(open(filename, 'rb'))\n",
    "# result9 = loaded_model9.score(X_test, y_test)\n",
    "# print(result9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest gridsearch1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='sqrt',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 3], 'min_samples_leaf': [2, 4],\n",
       "                         'n_estimators': [9, 18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid,cv=5)\n",
    "CV_rfc.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007587253414264 {'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 9}\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_, CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred15=CV_rfc.predict(X_train)\n",
    "y_pred16=CV_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29051   199]\n",
      " [ 3079   621]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7250   48]\n",
      " [ 773  167]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9005159332321699\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y_pred15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9003398883224083\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.27477876106194693\n",
      "\n",
      "Train data f1-score for class 'no' 0.9465949820788531\n",
      "\n",
      "Test data f1-score for class 'yes' 0.2891774891774892\n",
      "\n",
      "Test data f1-score for class 'no' 0.9464134194895895\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred15,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred15,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred16,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred16,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'rf_gridsearch_model1.sav'\n",
    "# pickle.dump(CV_rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model10 = pickle.load(open(filename, 'rb'))\n",
    "# result10 = loaded_model10.score(X_test, y_test)\n",
    "# print(result10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=0.8, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM_model = GradientBoostingClassifier(n_estimators=50,\n",
    "                                       learning_rate=0.3,\n",
    "                                       subsample=0.8)\n",
    "GBM_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred17 = GBM_model.predict(X_train)\n",
    "y_pred18 = GBM_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train set:\n",
      "0.925371775417299\n",
      "Accuracy for Test set:\n",
      "0.9155134741442098\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Train set:\")\n",
    "print(accuracy_score(y_train,y_pred17))\n",
    "\n",
    "print(\"Accuracy for Test set:\")\n",
    "print(accuracy_score(y_test,y_pred18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.6344581537089341\n",
      "\n",
      "Train data f1-score for class 'no' 0.9584438848799284\n",
      "\n",
      "Test data f1-score for class 'yes' 0.5929824561403508\n",
      "\n",
      "Test data f1-score for class 'no' 0.9528646891507516\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred17,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred17,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred18,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred18,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'gbm_model.sav'\n",
    "# pickle.dump(GBM_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model11 = pickle.load(open(filename, 'rb'))\n",
    "# result11 = loaded_model11.score(X_test, y_test)\n",
    "# print(result11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model in use\n",
    "GBM = GradientBoostingClassifier() \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\"n_estimators\" : [100,150],\n",
    "              \"max_depth\" : [5, 10],\n",
    "              \"learning_rate\" : [0.1,0.2]\n",
    "             } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.2], 'max_depth': [5, 10],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_GBM = GridSearchCV(estimator=GBM, param_grid=param_grid, cv=5)\n",
    "CV_GBM.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169044006069803 {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_gbm_model = CV_GBM.best_estimator_\n",
    "print(CV_GBM.best_score_, CV_GBM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred19 =best_gbm_model.predict(X_train)\n",
    "y_pred20=best_gbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942701062215478\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y_pred19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159990288905074\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.72218952324897\n",
      "\n",
      "Train data f1-score for class 'no' 0.9680563075257174\n",
      "\n",
      "Test data f1-score for class 'yes' 0.605473204104903\n",
      "\n",
      "Test data f1-score for class 'no' 0.952995516913463\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred19,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred19,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred20,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred20,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'gbm_gridsearch_model.sav'\n",
    "# pickle.dump(CV_GBM, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model12 = pickle.load(open(filename, 'rb'))\n",
    "# result12 = loaded_model12.score(X_test, y_test)\n",
    "# print(result12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.5,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model = XGBClassifier(n_estimators=500, \n",
    "                          gamma=0.5,\n",
    "                          learning_rate=0.1)\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred21 = XGB_model.predict(X_train)\n",
    "y_pred22 = XGB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train set:\n",
      "0.9317450682852807\n",
      "Accuracy for Test set:\n",
      "0.9162418062636563\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Train set:\")\n",
    "print(accuracy_score(y_train,y_pred21))\n",
    "\n",
    "print(\"Accuracy for Test set:\")\n",
    "print(accuracy_score(y_test,y_pred22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.664378450977466\n",
      "\n",
      "Train data f1-score for class 'no' 0.9620094934036048\n",
      "\n",
      "Test data f1-score for class 'yes' 0.6039035591274396\n",
      "\n",
      "Test data f1-score for class 'no' 0.9531695398398262\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred21,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred21,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred22,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred22,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'xgb_model.sav'\n",
    "# pickle.dump(XGB_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model13 = pickle.load(open(filename, 'rb'))\n",
    "# result13 = loaded_model13.score(X_test, y_test)\n",
    "# print(result13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(n_jobs=-1)\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {'colsample_bytree': [0.5, 0.9],\n",
    "              'n_estimators':[100],\n",
    "              'max_depth': [10, 15]\n",
    "             } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.9], 'max_depth': [10, 15],\n",
       "                         'n_estimators': [100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_XGB = GridSearchCV(estimator=XGB, param_grid=param_grid, cv= 10)\n",
    "CV_XGB.fit(X = X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9150227617602428 {'colsample_bytree': 0.9, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_xgb_model = CV_XGB.best_estimator_\n",
    "print(CV_XGB.best_score_, CV_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred23 =best_xgb_model.predict(X_train)\n",
    "y_pred24=best_xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797572078907435\n",
      "0.9128429230395727\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y_pred23))\n",
    "print(accuracy_score(y_test,y_pred24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.9052422219065208\n",
      "\n",
      "Train data f1-score for class 'no' 0.9886682183449144\n",
      "\n",
      "Test data f1-score for class 'yes' 0.5984340044742729\n",
      "\n",
      "Test data f1-score for class 'no' 0.9511165577342048\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred23,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred23,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred24,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred24,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'XGB_gridsearch_model.sav'\n",
    "# pickle.dump(CV_XGB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model14 = pickle.load(open(filename, 'rb'))\n",
    "# result14 = loaded_model14.score(X_test, y_test)\n",
    "# print(result14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1, n_estimators=600, random_state=None)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adaboost_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n",
    "                                    n_estimators = 600,\n",
    "                                    learning_rate = 1)\n",
    "\n",
    "Adaboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred25 = Adaboost_model.predict(X_train)\n",
    "y_pred26 = Adaboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train set:\n",
      "0.9420333839150228\n",
      "Accuracy for Test set:\n",
      "0.9087157076960427\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Train set:\")\n",
    "print(accuracy_score(y_train,y_pred25))\n",
    "\n",
    "print(\"Accuracy for Test set:\")\n",
    "print(accuracy_score(y_test,y_pred26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.7236689814814814\n",
      "\n",
      "Train data f1-score for class 'no' 0.9676205329897607\n",
      "\n",
      "Test data f1-score for class 'yes' 0.5775280898876404\n",
      "\n",
      "Test data f1-score for class 'no' 0.9488296135002722\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred25,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred25,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred26,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred26,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Adaboost_model.sav'\n",
    "# pickle.dump(Adaboost_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model15 = pickle.load(open(filename, 'rb'))\n",
    "# result15 = loaded_model15.score(X_test, y_test)\n",
    "# print(result15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model in use\n",
    "ADB = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2))\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {'n_estimators' : [100, 150],\n",
    "              'learning_rate' : [0.1, 0.5]\n",
    "             } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=2,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.5],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_ADB = GridSearchCV(estimator=ADB, \n",
    "                      param_grid=param_grid, \n",
    "                      cv=5,\n",
    "                      n_jobs=-1\n",
    "                     )\n",
    "\n",
    "CV_ADB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9150531107738998 {'learning_rate': 0.5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_adb_model = CV_ADB.best_estimator_\n",
    "print(CV_ADB.best_score_, CV_ADB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred27 =best_adb_model.predict(X_train)\n",
    "y_pred28 =best_adb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9229742033383915\n",
      "0.9136926438455936\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y_pred27))\n",
    "print(accuracy_score(y_test,y_pred28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data f1-score for class 'yes' 0.6183458646616541\n",
      "\n",
      "Train data f1-score for class 'no' 0.9571645569620253\n",
      "\n",
      "Test data f1-score for class 'yes' 0.584938704028021\n",
      "\n",
      "Test data f1-score for class 'no' 0.951839057102215\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred27,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred27,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred28,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred28,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'ADB_gridsearch_model.sav'\n",
    "# pickle.dump(CV_ADB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model16 = pickle.load(open(filename, 'rb'))\n",
    "# result16 = loaded_model16.score(X_test, y_test)\n",
    "# print(result16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store and load models sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# saved_model = pickle.dumps(knn) \n",
    "  \n",
    "# Load the pickled model \n",
    "# knn_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# # Use the loaded pickled model to make predictions \n",
    "# knn_from_pickle.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"alpha\" : [1e-2, 1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regressor = GridSearchCV(ridge, parameters, cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RidgeClassifier(alpha=1.0, class_weight=None,\n",
       "                                       copy_X=True, fit_intercept=True,\n",
       "                                       max_iter=None, normalize=False,\n",
       "                                       random_state=None, solver='auto',\n",
       "                                       tol=0.001),\n",
       "             iid='warn', n_jobs=None, param_grid={'alpha': [0.01, 1, 2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "0.9056449165402124\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred29 =ridge_regressor.predict(X_train)\n",
    "y_pred30 =ridge_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9059180576631259\n",
      "0.9089584850691915\n",
      "\n",
      "Train data f1-score for class 'yes' 0.42464736451373425\n",
      "\n",
      "Train data f1-score for class 'no' 0.9487704918032788\n",
      "\n",
      "Test data f1-score for class 'yes' 0.44690265486725667\n",
      "\n",
      "Test data f1-score for class 'no' 0.9503968253968254\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y_pred29))\n",
    "print(accuracy_score(y_test,y_pred30))\n",
    "\n",
    "print(\"\\nTrain data f1-score for class 'yes'\",f1_score(y_train,y_pred29,pos_label=\"yes\"))\n",
    "print(\"\\nTrain data f1-score for class 'no'\",f1_score(y_train,y_pred29,pos_label=\"no\"))\n",
    "\n",
    "print(\"\\nTest data f1-score for class 'yes'\",f1_score(y_test,y_pred30,pos_label=\"yes\"))\n",
    "print(\"\\nTest data f1-score for class 'no'\",f1_score(y_test,y_pred30,pos_label=\"no\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Rigdge_gridsearch_model.sav'\n",
    "# pickle.dump(ridge_regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model17 = pickle.load(open(filename, 'rb'))\n",
    "# result17 = loaded_model17.score(X_test, y_test)\n",
    "# print(result17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = pd.DataFrame([y_pred9,y_pred15,y_pred17,y_pred21,y_pred27])\n",
    "stack_test = pd.DataFrame([y_pred10,y_pred16,y_pred18,y_pred22,y_pred28])\n",
    "#stacked_pred_train = mode(stack_train,axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = stack_train.T\n",
    "stack_test = stack_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train.columns = ['SVC','RF','GBM','XGB','ADB']\n",
    "stack_test.columns = ['SVC','RF','GBM','XGB','ADB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SVC  RF  GBM  XGB  ADB\n",
      "0      no  no   no   no   no\n",
      "1      no  no  yes  yes  yes\n",
      "2      no  no   no   no   no\n",
      "3      no  no   no   no   no\n",
      "4      no  no   no   no   no\n",
      "5      no  no   no   no   no\n",
      "6      no  no  yes  yes  yes\n",
      "7      no  no   no   no   no\n",
      "8      no  no   no   no   no\n",
      "9      no  no   no   no   no\n",
      "10     no  no   no   no   no\n",
      "11     no  no  yes  yes  yes\n",
      "12     no  no   no   no   no\n",
      "13     no  no   no   no   no\n",
      "14     no  no   no   no   no\n",
      "15     no  no   no   no   no\n",
      "16     no  no   no   no   no\n",
      "17     no  no   no   no   no\n",
      "18     no  no   no   no   no\n",
      "19     no  no   no   no   no\n",
      "20     no  no   no   no   no\n",
      "21     no  no   no   no   no\n",
      "22     no  no   no   no   no\n",
      "23     no  no   no   no   no\n",
      "24     no  no   no   no   no\n",
      "25     no  no   no   no   no\n",
      "26     no  no   no   no   no\n",
      "27     no  no   no   no   no\n",
      "28     no  no   no   no   no\n",
      "29     no  no   no   no   no\n",
      "...    ..  ..  ...  ...  ...\n",
      "32920  no  no   no   no   no\n",
      "32921  no  no   no   no   no\n",
      "32922  no  no   no   no   no\n",
      "32923  no  no   no   no   no\n",
      "32924  no  no   no   no   no\n",
      "32925  no  no   no   no   no\n",
      "32926  no  no   no   no   no\n",
      "32927  no  no   no   no   no\n",
      "32928  no  no   no   no   no\n",
      "32929  no  no   no   no   no\n",
      "32930  no  no   no   no   no\n",
      "32931  no  no   no   no   no\n",
      "32932  no  no   no  yes  yes\n",
      "32933  no  no   no   no   no\n",
      "32934  no  no   no   no   no\n",
      "32935  no  no   no   no   no\n",
      "32936  no  no   no   no   no\n",
      "32937  no  no  yes  yes  yes\n",
      "32938  no  no   no   no   no\n",
      "32939  no  no   no   no   no\n",
      "32940  no  no   no   no   no\n",
      "32941  no  no   no   no   no\n",
      "32942  no  no   no   no   no\n",
      "32943  no  no   no   no   no\n",
      "32944  no  no   no   no   no\n",
      "32945  no  no   no   no   no\n",
      "32946  no  no   no   no   no\n",
      "32947  no  no   no   no   no\n",
      "32948  no  no   no   no   no\n",
      "32949  no  no  yes  yes  yes\n",
      "\n",
      "[32950 rows x 5 columns]\n",
      "      SVC   RF  GBM  XGB  ADB\n",
      "0      no   no   no   no   no\n",
      "1      no   no   no   no   no\n",
      "2      no   no   no   no   no\n",
      "3      no   no   no   no   no\n",
      "4      no   no   no   no   no\n",
      "5      no   no   no   no   no\n",
      "6      no   no   no   no   no\n",
      "7      no   no   no   no   no\n",
      "8     yes   no   no  yes  yes\n",
      "9      no   no   no   no   no\n",
      "10     no   no   no   no   no\n",
      "11     no   no   no   no   no\n",
      "12    yes  yes  yes  yes  yes\n",
      "13     no   no   no   no   no\n",
      "14     no   no   no   no   no\n",
      "15     no   no   no   no   no\n",
      "16     no   no   no   no   no\n",
      "17     no   no   no   no   no\n",
      "18     no   no   no   no   no\n",
      "19     no   no   no   no   no\n",
      "20     no   no   no   no   no\n",
      "21     no   no   no   no   no\n",
      "22     no   no   no   no   no\n",
      "23    yes   no  yes  yes  yes\n",
      "24     no   no   no   no   no\n",
      "25     no   no   no   no   no\n",
      "26     no   no   no   no   no\n",
      "27     no   no   no   no   no\n",
      "28     no   no   no   no   no\n",
      "29     no   no   no   no   no\n",
      "...   ...  ...  ...  ...  ...\n",
      "8208   no   no   no   no   no\n",
      "8209   no   no  yes  yes  yes\n",
      "8210   no   no   no   no   no\n",
      "8211   no   no   no   no   no\n",
      "8212   no   no   no   no   no\n",
      "8213   no   no   no   no   no\n",
      "8214   no   no  yes  yes  yes\n",
      "8215   no   no   no   no   no\n",
      "8216   no   no   no   no   no\n",
      "8217   no   no   no   no   no\n",
      "8218   no   no   no   no   no\n",
      "8219   no   no  yes   no   no\n",
      "8220   no   no   no   no   no\n",
      "8221   no   no   no   no   no\n",
      "8222   no   no   no   no   no\n",
      "8223   no   no   no   no   no\n",
      "8224   no   no   no   no   no\n",
      "8225   no   no  yes   no   no\n",
      "8226   no   no   no   no   no\n",
      "8227   no   no   no   no   no\n",
      "8228   no   no   no   no   no\n",
      "8229  yes   no   no   no   no\n",
      "8230   no   no   no   no   no\n",
      "8231   no   no   no   no   no\n",
      "8232   no   no  yes  yes  yes\n",
      "8233   no   no  yes   no  yes\n",
      "8234  yes   no  yes  yes  yes\n",
      "8235   no   no   no   no   no\n",
      "8236   no   no   no   no   no\n",
      "8237   no   no   no   no   no\n",
      "\n",
      "[8238 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stack_train)\n",
    "print(stack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train['SVC'] = label_encoder.fit_transform(stack_train['SVC'])\n",
    "stack_train['RF'] = label_encoder.fit_transform(stack_train['RF'])\n",
    "stack_train['GBM'] = label_encoder.fit_transform(stack_train['GBM'])\n",
    "stack_train['XGB'] = label_encoder.fit_transform(stack_train['XGB'])\n",
    "stack_train['ADB'] = label_encoder.fit_transform(stack_train['ADB'])\n",
    "\n",
    "stack_test['SVC'] = label_encoder.fit_transform(stack_test['SVC'])\n",
    "stack_test['RF'] = label_encoder.fit_transform(stack_test['RF'])\n",
    "stack_test['GBM'] = label_encoder.fit_transform(stack_test['GBM'])\n",
    "stack_test['XGB'] = label_encoder.fit_transform(stack_test['XGB'])\n",
    "stack_test['ADB'] = label_encoder.fit_transform(stack_test['ADB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "      <th>RF</th>\n",
       "      <th>GBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVC  RF  GBM  XGB  ADB\n",
       "0    0   0    0    0    0\n",
       "1    0   0    1    1    1\n",
       "2    0   0    0    0    0\n",
       "3    0   0    0    0    0\n",
       "4    0   0    0    0    0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = LogisticRegression()\n",
    "\n",
    "dtc.fit(stack_train,y_train)\n",
    "\n",
    "stacked_pred_train = dtc.predict(stack_train)\n",
    "stacked_pred_test = dtc.predict(stack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9299544764795145\n",
      "0.9161204175770818\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, stacked_pred_train))\n",
    "print(accuracy_score(y_test, stacked_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8052188858040593\n",
      "0.7742045306745556\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train,stacked_pred_train,average='macro'))\n",
    "\n",
    "print(f1_score(y_test,stacked_pred_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'logreg_ens_model.sav'\n",
    "# pickle.dump(dtc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model18 = pickle.load(open(filename, 'rb'))\n",
    "# result18 = loaded_model18.score(X_test, y_test)\n",
    "# print(result18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_error_report = {'Model':['LR_GS', 'NB', 'DT_GS', 'SVC_linear', 'SVC_rbf', 'RF', 'RF_GS', 'GBM', 'GBM_GS', 'XGB', 'XGB_GS', 'ADB', 'ADB_GS', 'RIDGE', 'ENSEMBLE'], \n",
    "                               'Train_Accuracy':[0.9, 0.71, 0.918, 0.901, 0.907, 0.92, 0.902, 0.92, 0.94, 0.93, 0.97, 0.94, 0.92, 0.9, 0.92],\n",
    "                               'Test_Accuracy':[0.91, 0.71, 0.914, 0.903, 0.909, 0.91, 0.903, 0.91, 0.91, 0.91, 0.91, 0.90, 0.91, 0.9, 0.91],\n",
    "                               'Train_f1_score_class_yes':[0.72, 0.606, 0.786, 0.38, 0.42, 0.52, 0.32, 0.62, 0.72, 0.66, 0.9, 0.72, 0.61, 0.42, 0.8],\n",
    "                               'Train_f1_score_class_no':[0.72, 0.606, 0.786, 0.94, 0.94, 0.95, 0.94, 0.95, 0.96, 0.96, 0.98, 0.96, 0.95, 0.94, 0.8],\n",
    "                               'Test_f1_score_class_yes':[0.73, 0.605, 0.782, 0.4, 0.45, 0.49, 0.33, 0.59, 0.6, 0.6, 0.59, 0.57, 0.58, 0.44, 0.77],\n",
    "                               'Test_f1_score_class_no':[0.73, 0.605, 0.782, 0.94, 0.95, 0.95, 0.94, 0.95, 0.95, 0.95, 0.95, 0.94, 0.95, 0.95, 0.77]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Train_f1_score_class_yes</th>\n",
       "      <th>Train_f1_score_class_no</th>\n",
       "      <th>Test_f1_score_class_yes</th>\n",
       "      <th>Test_f1_score_class_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_GS</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT_GS</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_rbf</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Train_Accuracy  Test_Accuracy  Train_f1_score_class_yes  \\\n",
       "0       LR_GS           0.900          0.910                     0.720   \n",
       "1          NB           0.710          0.710                     0.606   \n",
       "2       DT_GS           0.918          0.914                     0.786   \n",
       "3  SVC_linear           0.901          0.903                     0.380   \n",
       "4     SVC_rbf           0.907          0.909                     0.420   \n",
       "\n",
       "   Train_f1_score_class_no  Test_f1_score_class_yes  Test_f1_score_class_no  \n",
       "0                    0.720                    0.730                   0.730  \n",
       "1                    0.606                    0.605                   0.605  \n",
       "2                    0.786                    0.782                   0.782  \n",
       "3                    0.940                    0.400                   0.940  \n",
       "4                    0.940                    0.450                   0.950  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.DataFrame(classification_error_report) \n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating excel file of classification report\n",
    "#report.to_excel(\"Classification_report.xlsx\",engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
